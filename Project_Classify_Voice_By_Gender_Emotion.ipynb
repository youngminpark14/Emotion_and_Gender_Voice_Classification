{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify Voice By Gender & Emotion\n",
    "\n",
    "<h3><span style=\"color:green\">For SDSU CS 450: Intro to AI</span></h3>\n",
    "<h3><span style=\"color:green\">Authors: Noah Nielsen, Young Min Park, Dylan Murphy, Elijah Pearce, ALex Colmenar  </span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">Domain & Problem Described</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is in the domain of speech processing and classification<br>\n",
    "We will train a classifer to predict the speaker's gender and/or emotion in a voice sample in the multiple languages including spanish, german, english, russian<br>\n",
    "We will compare the accuracy when predicting gender alone, emotion alone, and gender and emotion together\n",
    "\n",
    "From the results, we will form hypotheses about why we think the results are what they are<br>\n",
    "We will also try several methods to optimize the accuracy. We will then compare our optimized and uptomized results<br>\n",
    "and propose why our optimization methods improved the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">Dataset Described</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset consists of 7 emotion categories: <br>1) anger; 2) fear; 3) enthusiasm; 4) happiness; 5) sadness; 6) disgust; and 7) neutral. \n",
    "The files are in the .wav (uncomprossed, high-quality) format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">Workflow Described</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Split dataset into train & test subsets\n",
    "#### 3A. Use Librosa library to extract features from the voice data\n",
    "#### 3B. Exploratory Data Analysis: Plot the Principal Components\n",
    "#### 4A.  Build and train a classifier\n",
    "#### 4B.  Compare the accuracy across the prediction scenarios\n",
    "#### 5. Optimize the classifier, analyze the effect\n",
    "#### 6. Draw conclusion about the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">0. Install Libraries</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Library      | Description                                                     |\n",
    "|--------------|-----------------------------------------------------------------|\n",
    "| scikit-learn | Machine learning library used to run the classification algo    |\n",
    "| numpy        | Array and numerical analysis library                            |\n",
    "| pandas       | Library that puts data into structured DataFrame objects      |\n",
    "| matplotlib   | Library used to plot numerical data                             |\n",
    "| seaborn      | Extends matplotlib to allow for creating more complex plots     |\n",
    "|              |                                                                 |\n",
    "| librosa      | Audio processing library that can extract, modify, and plot sound features |\n",
    "\n",
    "#### Uncomment the code below and install the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/youngminpark/micromamba/lib/python3.9/site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy in /Users/youngminpark/micromamba/lib/python3.9/site-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /Users/youngminpark/micromamba/lib/python3.9/site-packages (2.3.1)\n",
      "Requirement already satisfied: matplotlib in /Users/youngminpark/micromamba/lib/python3.9/site-packages (3.9.4)\n",
      "Requirement already satisfied: seaborn in /Users/youngminpark/micromamba/lib/python3.9/site-packages (0.13.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: librosa in /Users/youngminpark/micromamba/lib/python3.9/site-packages (0.11.0)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (0.60.0)\n",
      "Requirement already satisfied: numpy>=1.22.3 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.1.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (1.5.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (0.13.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (0.5.0.post1)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (4.12.2)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (0.4)\n",
      "Requirement already satisfied: msgpack>=1.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: packaging in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from lazy_loader>=0.1->librosa) (24.1)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from pooch>=1.1->librosa) (4.2.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from pooch>=1.1->librosa) (2.32.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from scikit-learn>=1.1.0->librosa) (3.6.0)\n",
      "Requirement already satisfied: cffi>=1.0 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from soundfile>=0.12.1->librosa) (1.17.0)\n",
      "Requirement already satisfied: pycparser in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/youngminpark/micromamba/lib/python3.9/site-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn numpy pandas matplotlib seaborn\n",
    "!pip install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">1. Obtain Dataset</span></h3>\n",
    "\n",
    "#### Procedure\n",
    "\n",
    "When you receive this Notebook file, you should also receive the **emodb.zip** dataset. If not, download the dataset from\n",
    "\n",
    "https://www.kaggle.com/datasets/piyushagni5/berlin-database-of-emotional-speech-emodb (Need Kaggle account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'emodb.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdest_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m already populated – skipping extraction.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mextract_zip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43memodb.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdatasets/emodb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m extract_zip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMACHINlEARNINGdATA.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/mldata\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m, in \u001b[0;36mextract_zip\u001b[0;34m(zip_path, dest_dir)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 2. Extract only if the folder is still empty\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(dest_dir):\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mzipfile\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mZipFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m z:\n\u001b[1;32m     16\u001b[0m         z\u001b[38;5;241m.\u001b[39mextractall(dest_dir)\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdest_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/lib/python3.9/zipfile.py:1250\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m   1249\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1250\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilemode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filemode \u001b[38;5;129;01min\u001b[39;00m modeDict:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'emodb.zip'"
     ]
    }
   ],
   "source": [
    "import os, zipfile\n",
    "\n",
    "def extract_zip(zip_path, dest_dir):\n",
    "    \"\"\"\n",
    "    Unzips *zip_path* into *dest_dir* (creates it if missing)\n",
    "    and skips extraction if dest_dir already contains files.\n",
    "    \"\"\"\n",
    "    # 1. Make the folder if it doesn't exist\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "        print(f\"Made directory {dest_dir}\")\n",
    "\n",
    "    # 2. Extract only if the folder is still empty\n",
    "    if not os.listdir(dest_dir):\n",
    "        with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "            z.extractall(dest_dir)\n",
    "            print(f\"Extracted {zip_path} → {dest_dir}\")\n",
    "    else:\n",
    "        print(f\"{dest_dir} already populated – skipping extraction.\")\n",
    "        \n",
    "extract_zip(\"emodb.zip\",   \"datasets/emodb\")\n",
    "extract_zip(\"MACHINlEARNINGdATA.zip\", \"datasets/mldata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">2. Split Dataset into Train & Test Subsets</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, itertools, pprint\n",
    "pprint.pprint(\n",
    "    list(itertools.islice(\n",
    "        glob.glob(\"datasets/mldata/**/*.wav\", recursive=True), 20))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure\n",
    "\n",
    "Populate train_filenames and test_filenames by naming each voice sample into either\n",
    "the training or test subset.<br>\n",
    "From each voice sample's filename, extract its gender label and emotion label (ie each speaker ID is specifically<br>\n",
    "noted in the emodb documentation to belong to a male or female speaker).<br>\n",
    "\n",
    "The result will be 6 lists: train_filenames, test_filenames, train_gender_labels, test_gender_labels, train_emotion_labels, test_emotion_labels.\n",
    "\n",
    "The ratio of training : test samples will be 5:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1)  Dataset‑specific filename parsers\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "EMO_RAVDESS = {\n",
    "    \"01\": \"neutral\",\n",
    "    \"02\": \"calm\",\n",
    "    \"03\": \"happy\",\n",
    "    \"04\": \"sad\",\n",
    "    \"05\": \"angry\",\n",
    "    \"06\": \"fearful\",\n",
    "    \"07\": \"disgust\",\n",
    "    \"08\": \"surprised\",\n",
    "}\n",
    "\n",
    "def parse_emodb(path: str):\n",
    "    fname = os.path.basename(path)\n",
    "    gender = \"Female\" if fname[:2] in {\"08\",\"09\",\"13\",\"14\",\"16\"} else \"Male\"\n",
    "    emotion = fname[5].lower()\n",
    "    return gender, emotion\n",
    "\n",
    "def parse_ravdess(path: str):\n",
    "    \"\"\"\n",
    "    Works for filenames like .../Anger/03-01-05-01-01-01-16.wav\n",
    "    Returns (gender, emotion)\n",
    "    \"\"\"\n",
    "    fname = os.path.basename(path)\n",
    "    parts = fname.split('-')                     # ['03','01','05','01','01','01','16.wav']\n",
    "    if len(parts) < 7:\n",
    "        raise ValueError(f\"Unexpected RAVDESS name: {fname}\")\n",
    "\n",
    "    emotion_code = parts[2]                     # '05'\n",
    "    actor_id     = int(parts[-1].split('.')[0]) # 16\n",
    "    gender       = \"Male\" if actor_id % 2 else \"Female\"\n",
    "    emotion      = EMO_RAVDESS.get(emotion_code, \"unknown\")\n",
    "    return gender, emotion\n",
    "\n",
    "def parse_auto(path: str):\n",
    "    \"\"\"\n",
    "    Chooses the correct parser based on the filename:\n",
    "      • filenames that contain a dash ('-')   → RAVDESS format\n",
    "      • filenames without a dash              → Emo‑DB format\n",
    "    \"\"\"\n",
    "    fname = os.path.basename(path)\n",
    "    if '-' in fname:\n",
    "        return parse_ravdess(path)\n",
    "    else:\n",
    "        return parse_emodb(path)\n",
    "# ------------------------------------------------------------------\n",
    "# 2)  Register every corpus you want to merge\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "DATASETS = {\n",
    "    \"emodb\" : {\"root\": \"datasets/emodb\",                       \"parser\": parse_emodb},\n",
    "    \"mldata\": {\"root\": \"datasets/mldata/MACHINlEARNINGdATA\",   \"parser\": parse_auto},\n",
    "    # add more here …\n",
    "}\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 3)  Walk *all* roots and collect files + labels\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "filenames, gender_labels, emotion_labels, dataset_labels = [], [], [], []\n",
    "\n",
    "for ds_name, cfg in DATASETS.items():\n",
    "    root, parser = cfg[\"root\"], cfg[\"parser\"]\n",
    "\n",
    "    for cur_dir, _, files in os.walk(root):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(\".wav\"):\n",
    "                full_path = os.path.join(cur_dir, f)\n",
    "\n",
    "                gender, emotion = parser(full_path)   # ← pass full path!\n",
    "                filenames.append(full_path)\n",
    "                gender_labels.append(gender)\n",
    "                emotion_labels.append(emotion)\n",
    "                dataset_labels.append(ds_name)\n",
    "\n",
    "print(f\"Total .wav files across datasets: {len(filenames)}\")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4)  Train / test split\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "(train_filenames, test_filenames,\n",
    " train_gender_labels,  test_gender_labels,\n",
    " train_emotion_labels, test_emotion_labels,\n",
    " train_dataset_labels, test_dataset_labels) = train_test_split(\n",
    "     filenames, gender_labels,\n",
    "     emotion_labels, dataset_labels,\n",
    "     test_size=0.167, random_state=42, shuffle=True\n",
    " )\n",
    "\n",
    "print(f\"Training samples : {len(train_filenames)}\")\n",
    "print(f\"Testing  samples : {len(test_filenames)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">3. Exploratory Data Analysis</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure\n",
    "\n",
    "Separately analyze the distribution of emotions and genders in the dataset. Make these observations of the results:<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "def extract_labels_from_filename(filenames):\n",
    "    emotions = []\n",
    "    genders = []\n",
    "    for filename in filenames:\n",
    "        basename = os.path.basename(filename)\n",
    "        gender = \"Female\" if basename[:2] in [\"08\", \"09\", \"13\", \"14\", \"16\"] else \"Male\"\n",
    "        emotion = basename[5]\n",
    "        emotions.append(emotion)\n",
    "        genders.append(gender)\n",
    "    return emotions, genders\n",
    "\n",
    "train_emotions, train_genders = extract_labels_from_filename(train_filenames)\n",
    "test_emotions, test_genders = extract_labels_from_filename(test_filenames)\n",
    "\n",
    "emotion_counts = collections.Counter(train_emotions)\n",
    "gender_counts = collections.Counter(train_genders)\n",
    "print(\"Emotion counts:\", emotion_counts)\n",
    "print(\"Gender  counts:\", gender_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure\n",
    "\n",
    "Extract the Mel-Frequency Cepstral Coefficients of each voice sample using the Librosa module.<br>\n",
    "MFCCs capture the short-term power spectrum of a sound. It essentially captures the intensity/energy distributions<br>\n",
    "of the most relevant frequencies in a sound. The sound is splitted into small, overlapping windows and the spectrum of<br>\n",
    "each window is computed. This allows us to observe how the frequency changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "def extract_mfccs(file_path, n_mfcc=13):\n",
    "    y, sr = librosa.load(file_path, sr=None) \n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc)\n",
    "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
    "    return mfccs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [extract_mfccs(f) for f in train_filenames]\n",
    "X_test  = [extract_mfccs(f) for f in test_filenames]\n",
    "\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure\n",
    "\n",
    "Merge the gender and emotion labels to allow multiclass prediction (predict both together)<br>\n",
    "Then do Principal Component Analysis on the MFCC features.<br>\n",
    "\n",
    "First, normalize each feature to have mean of 0.0 and standard deviation of 1.0 <br>\n",
    "PCA transform the high-dimensional data into just two principal components<br>\n",
    "\n",
    "Observe that the first principal component captures more than a third of the information (= 0.375),<br>\n",
    "and the first two components capture half of the information. We will need to use more if we want to <br>\n",
    "capture anywhere close to the full information in the data, which further component has smaller\n",
    "marginal benefit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined_labels = [f\"{gender}-{emotion}\" for gender, emotion in zip(train_gender_labels, train_emotion_labels)]\n",
    "test_combined_labels  =  [f\"{gender}-{emotion}\" for gender, emotion in zip(test_gender_labels, test_emotion_labels)]\n",
    "\n",
    "print(train_combined_labels[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Standardize (normalize) the MFCC features\n",
    "scaler = StandardScaler()\n",
    "X_train_standardized = scaler.fit_transform(X_train)\n",
    "\n",
    "# Step 2: Apply PCA to reduce dimensionality to 6 components\n",
    "pca = PCA(n_components=6)\n",
    "X_train_6d = pca.fit_transform(X_train_standardized)\n",
    "\n",
    "# Step 3: Create a DataFrame for visualization (only use the first 2 components for the plot)\n",
    "df = pd.DataFrame(X_train_6d, columns=[f'PC{i+1}' for i in range(6)])  # Add all 6 PCs as columns\n",
    "df['Combined_Label'] = train_combined_labels  # Assuming you have these labels\n",
    "\n",
    "# Step 4: Plot the first 2 principal components (PC1 and PC2)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='Combined_Label', data=df, palette='viridis', s=60)\n",
    "plt.title('2D PCA of MFCC Features by Combined Label (First 2 PCs)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "# Optional: Check how much variance is explained by each principal component\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">4. Support Vector Machines Model</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure\n",
    "\n",
    "We use Support Vector Machines as our prediction model <br>\n",
    "\n",
    "Imagine the data as being points on a hyperspace of dimensions D up to the number of features of the data (ie 13)<br>\n",
    "The goal is to draw a hyperplane of dimensions (D - 1) that best separate the classes based on a metric.<br>\n",
    "The separating hyperplane is the **decision boundary** and the metric is the **kernel function**.<br>\n",
    "We use only points that are closest to any particular decision boundary we choose, these points being the support vectors<br>\n",
    "Sometimes can we cannot draw a linear hyperplane, we can define a kernel function that results in a decision<br>\n",
    "boundary that is curved, but that works better to distinguish the classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Gender classifier\n",
    "gender_clf = SVC(kernel='linear')\n",
    "gender_clf.fit(X_train, train_gender_labels)\n",
    "gender_pred = gender_clf.predict(X_test)\n",
    "gender_accuracy = accuracy_score(test_gender_labels, gender_pred)\n",
    "print(f'Gender Prediction Accuracy: {gender_accuracy * 100:.2f}%')\n",
    "\n",
    "# Emotion classifier\n",
    "emotion_clf = SVC(kernel='linear')\n",
    "emotion_clf.fit(X_train, train_emotion_labels)\n",
    "emotion_pred = emotion_clf.predict(X_test)\n",
    "emotion_accuracy = accuracy_score(test_emotion_labels, emotion_pred)\n",
    "print(f'Emotion Prediction Accuracy: {emotion_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "As we can see, a SVM model almost perfectly predicts the gender of a sample based on its MFCCS features\n",
    "This should not be suprisingly because:\n",
    "1. Gender prediction involves just 2 classes. Just a random guess would result in an accuracy of ~50%\n",
    "2. The information relating to gender is more incisive. The differences between male and female voices in relation to<br>\n",
    "pitch, tone, and range just larger. These differences are biological and thus are even present in different languages.\n",
    "\n",
    "Compare that to the accuracy in emotion classification (96.67% for gender vs 43% for gender):\n",
    "1. Emotions and ways humans exhibit emotions, especially by voice, is complex (ie sarcasm).<br>\n",
    "How humans exhibit emotion vary across individuals and cultures. These differences will cloud the data\n",
    "2. Different emotions may sound very similar, for example anger vs. fear or happiness vs. surprise. For instance,<br> angry and\n",
    "fearful voices may both show higher pitch, fast speech rate, and loud volume.\n",
    "3. The target labels for emotion involve 6 classes, more than the 2 for gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Normalize the Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Step 2: Hyperparameter Tuning for Gender Classifier\n",
    "param_grid = {\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [0.001, 0.01, 0.1, 1]  # Only applies to 'rbf' kernel\n",
    "}\n",
    "\n",
    "gender_clf = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "gender_clf.fit(X_train_scaled, train_gender_labels)\n",
    "\n",
    "# Evaluate Gender Classifier\n",
    "best_gender_clf = gender_clf.best_estimator_\n",
    "gender_pred = best_gender_clf.predict(X_test_scaled)\n",
    "gender_accuracy = accuracy_score(test_gender_labels, gender_pred)\n",
    "print(f'Best Parameters for Gender Classifier: {gender_clf.best_params_}')\n",
    "print(f'Gender Prediction Accuracy: {gender_accuracy * 100:.2f}%')\n",
    "\n",
    "# Hyperparameter Tuning for Emotion Classifier\n",
    "emotion_clf = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "emotion_clf.fit(X_train_scaled, train_emotion_labels)\n",
    "\n",
    "# Evaluate Emotion Classifier\n",
    "best_emotion_clf = emotion_clf.best_estimator_\n",
    "emotion_pred = best_emotion_clf.predict(X_test_scaled)\n",
    "emotion_accuracy = accuracy_score(test_emotion_labels, emotion_pred)\n",
    "print(f'Best Parameters for Emotion Classifier: {emotion_clf.best_params_}')\n",
    "print(f'Emotion Prediction Accuracy: {emotion_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Procedure\n",
    "\n",
    "We attempt to optimize the accuracy of our step by 1. normalizing our data, 2. tuning our hyperparameters\n",
    "1. Normalizing improve results because it modify the features to have the same scale. Thus, a feature with larger<br>\n",
    "magnitude of values will not dominate another feature with smaller magnitude of values.\n",
    "\n",
    "2. Hyperparameters tuning is simply running the model with different parameters to find the combination that gives the <br>\n",
    "best result. GridSearchCV does this for us (run all combinations) rather than us having to run our own loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "As we can see, our 2-step optimization cause a negligible effect on the accuracy of gender prediction.<br>\n",
    "But normalizing the data and tuning the hyperparameters improve the accuracy of emotion classification to a small but significant degree<br>\n",
    "\n",
    "Why do we think? Because gender classification is a straighforward problem, there's not much that can be done to improve<br>\n",
    "the prediction except by training on more data (which we cannot do). But because emotion prediction is a more complex problem,<br>there's more room for us to use tricks to improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 1)  Unified mapping → 7 target classes\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "TARGET_MAP = {\n",
    "    # --- Emo‑DB single‑letter codes ---\n",
    "    'W': 'anger',\n",
    "    'E': 'disgust',\n",
    "    'F': 'happy',\n",
    "    'T': 'sad',\n",
    "    'N': 'neutral',\n",
    "    'A': 'fear/anxious',\n",
    "    'L': 'other',           # bored  → other\n",
    "\n",
    "    # --- RAVDESS / word labels ---\n",
    "    'angry'    : 'anger',\n",
    "    'disgust'  : 'disgust',\n",
    "    'happy'    : 'happy',\n",
    "    'sad'      : 'sad',\n",
    "    'neutral'  : 'neutral',\n",
    "    'fearful'  : 'fear/anxious',\n",
    "    'anxious'  : 'fear/anxious',\n",
    "\n",
    "    # everything else goes to 'other'\n",
    "    'bored'    : 'other',\n",
    "    'calm'     : 'other',\n",
    "    'surprised': 'other',\n",
    "}\n",
    "\n",
    "def to_target(label):\n",
    "    \"\"\"Map raw label to one of the 7 target classes.\"\"\"\n",
    "    return TARGET_MAP.get(label, 'other')\n",
    "\n",
    "# Map ground‑truth and predictions\n",
    "mapped_true  = [to_target(lbl) for lbl in test_emotion_labels]\n",
    "mapped_pred  = [to_target(lbl) for lbl in emotion_pred]\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# 2)  Confusion matrix over the 7 categories\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "targets = ['anger', 'disgust', 'happy', 'sad',\n",
    "           'neutral', 'fear/anxious', 'other']\n",
    "\n",
    "cm_norm = confusion_matrix(mapped_true, mapped_pred,\n",
    "                           labels=targets, normalize='true')\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm_norm, display_labels=targets)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation=45)\n",
    "plt.title('Normalized Confusion Matrix (7‑class emotion set)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">5. SVM: Multiclass Classification</span></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning for Combined Classifier\n",
    "combined_clf = GridSearchCV(SVC(), param_grid, cv=5)\n",
    "combined_clf.fit(X_train_scaled, train_combined_labels)\n",
    "\n",
    "# Evaluate Combined Classifier\n",
    "best_combined_clf = combined_clf.best_estimator_\n",
    "combined_pred = best_combined_clf.predict(X_test_scaled)\n",
    "combined_accuracy = accuracy_score(test_combined_labels, combined_pred)\n",
    "\n",
    "print(f'Best Parameters for Combined Classifier: {combined_clf.best_params_}')\n",
    "print(f'Combined Prediction Accuracy: {combined_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis\n",
    "\n",
    "We combine the gender and emotion labels and train a SVM model to predict them together\n",
    "\n",
    "At first glance, it was suprising that the accuracy of predicting both gives a similar accuracy to that obtained when we\n",
    "try to predict only emotion<br>\n",
    "We expected the combined accuracy to be lower than either individual accuracy. However, thinking it over more, the result is not that suprising<br>\n",
    "Gender accuracy is nearly 100%. Functionally, it is a given that a SVM model can effortlessly predict the gender correctly\n",
    "\n",
    "If we view it like that, predicting gender X and gender together is like predicting X alone and we get a similar accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">6. Conclusion</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We successfully built gender and emotion classifiers for the German language, trained on the emodb voice dataset<br>\n",
    "We used Support Vector Machines as our algorithm and obtained results that are respectable (96.67%, 70.00%)\n",
    "\n",
    "We verified things we suspected or would not be suprised by:\n",
    "1. emotion prediction is a more difficult problem than gender prediction.\n",
    "2. attempts to optimize a model will improve its performance for a complex problem, but will produce little to no benefit for a simpler problem\n",
    "3. Predicting gender is so effortless that multiclass prediction of gender and X is like predicting X alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><span style=\"color:red\">Sources & Documentation</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://medium.com/@derutycsl/intuitive-understanding-of-mfccs-836d36a1f779\n",
    "#### https://librosa.org/doc/0.9.2/generated/librosa.feature.mfcc.html\n",
    "#### https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
    "#### https://seaborn.pydata.org/generated/seaborn.scatterplot.html\n",
    "#### https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "#### https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "#### https://scikit-learn.org/1.5/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### https://www.kaggle.com/datasets/uwrfkaggler/ravdess-emotional-speech-audio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### https://wwww.kaggle.com/datasets/piyushagni5/berlin-database-of-emotional-speech-emodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
